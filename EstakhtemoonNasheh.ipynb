{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af07107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "import torch.nn.functional as FF\n",
    "import torch.nn as nn\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7962d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "# from google.colab import drive\n",
    "import os\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\")\n",
    "# os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\")\n",
    "# os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\")\n",
    "# os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\")\n",
    "# os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\")\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e26cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.image_foldernames = list(self.labels[\"id\"])\n",
    "#         print(self.image_foldernames)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_foldernames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tmplistofImages = []\n",
    "        for filename in os.listdir(self.image_dir+\"/\"+str(self.image_foldernames[idx])):\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(self.image_dir+\"/\"+str(self.image_foldernames[idx]), filename)\n",
    "                img = read_image(img_path)\n",
    "                image = tv_tensors.Image(img).to(torch.float32)\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                    tmplistofImages.append(image)\n",
    "                    \n",
    "        if len(tmplistofImages)<10:\n",
    "            for i in range(10-len(tmplistofImages)):\n",
    "                tmplistofImages.append(image)\n",
    "                \n",
    "        stacked_images = torch.cat(tmplistofImages, dim=0)\n",
    "        # Get the 4-class labels for this image\n",
    "        row = self.labels.iloc[idx]\n",
    "        labels = torch.tensor(row[\"pool\"], dtype=torch.int64)\n",
    "        return stacked_images, labels\n",
    "\n",
    "\n",
    "class CustomImageDatasettest(Dataset):\n",
    "    def __init__(self, image_dir, labels, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.image_foldernames = list(self.labels[\"id\"])\n",
    "#         print(\"\\n\\n\",self.labels[\"id\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_foldernames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tmplistofImages = []\n",
    "        for filename in os.listdir(self.image_dir+\"/\"+str(self.image_foldernames[idx])):\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(self.image_dir+\"/\"+str(self.image_foldernames[idx]), filename)\n",
    "                img = read_image(img_path)\n",
    "                image = tv_tensors.Image(img).to(torch.float32)\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                    tmplistofImages.append(image)\n",
    "                    \n",
    "        if len(tmplistofImages)<10:\n",
    "            for i in range(10-len(tmplistofImages)):\n",
    "                tmplistofImages.append(image)\n",
    "                \n",
    "        stacked_images = torch.cat(tmplistofImages, dim=0)\n",
    "        return stacked_images,self.image_foldernames[idx]\n",
    "\n",
    "\n",
    "# Example transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "])\n",
    "\n",
    "def read_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def check_phrases(x, phrase_a, phrase_b):\n",
    "    # Check if either phrase_a or phrase_b is in the string x\n",
    "    if phrase_a in x or phrase_b in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "labels = read_json('C:/Users/ASUS/QueraContest/Q4/train.json')\n",
    "\n",
    "trainLabels = pd.DataFrame(columns=['id','pool'])\n",
    "for i in range(len(labels[\"rooms\"])):\n",
    "    tmpdict = dict(labels[\"rooms\"][i])\n",
    "    trainLabels.loc[len(trainLabels)] = [tmpdict[\"id\"],check_phrases(tmpdict[\"description\"], \"استخر\", \"استخردار\")]\n",
    "    \n",
    "# print(trainLabels)  \n",
    "dataset = CustomImageDataset(image_dir='C:/Users/ASUS/QueraContest/Q4/train', labels=trainLabels, transform=transform)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.001, random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "labels = read_json('C:/Users/ASUS/QueraContest/Q4/test.json')\n",
    "testLabels = pd.DataFrame(columns=['id'])\n",
    "for i in range(len(labels[\"rooms\"])):\n",
    "    tmpdict = labels[\"rooms\"][i]\n",
    "    testLabels.loc[len(testLabels)] = tmpdict[\"id\"]\n",
    "    \n",
    "# print(testLabels) \n",
    "dataset_testfinal = CustomImageDatasettest(image_dir='C:/Users/ASUS/QueraContest/Q4/test', labels=testLabels, transform=transform)\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "dataloader_test_final = DataLoader(dataset_testfinal, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d2adfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = FF.relu(self.bn1(self.conv1(x)))\n",
    "        out = FF.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = FF.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(30, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = FF.relu(self.bn1(self.conv1(x)))\n",
    "        x = FF.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x.view(x.size(0), 1, 2)\n",
    "\n",
    "def MultiOutputResNet101():\n",
    "    return ResNet(Bottleneck, [30, 1, 23, 2])\n",
    "\n",
    "model = MultiOutputResNet101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c138de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 8\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    counter =0\n",
    "    for inputs, info in dataloader:\n",
    "        inputs, info = inputs.to(device), info.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs[:,0,:], info)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        counter+=1\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/counter:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61879a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "counter = 0\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.eval()\n",
    "    correct_predictions = 0.0\n",
    "    for inputs, info in dataloader_test:\n",
    "        inputs, info = inputs.to(device), info.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs[:, 0, :], 1)\n",
    "        print(counter)\n",
    "        correct_predictions += (predicted == info).sum().item()\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba4e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(correct_predictions/counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "675390d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "df = pd.DataFrame(columns=['id','Pool'])\n",
    "counter = 0\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.eval()\n",
    "    correct_predictions = 0.0\n",
    "    for inputs,imageid in dataloader_test_final:\n",
    "        inputs,imageid = inputs.to(device),imageid.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs[:, 0, :], 1)\n",
    "        counter+=1\n",
    "        df.loc[len(df)] = [int(imageid.cpu()),int(predicted.cpu())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea9f82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.DataFrame({'id': df['id'], 'pool': df['Pool']==1})\n",
    "finaldf"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
